---
title: ES
copyright: true
tags:
  - Devops
  - linux
  - ES
categories: 'Devops, linux, ES'
abbrlink: 3eb5a9f1
date: 2019-09-14 08:30:20
---

2019-09-14-ElasticSearch
<!-- more -->

## rsync 同步服务：  
### rsync基本使用：
| 选项 | 说明         |
|------|------------|
| -a   | 归档模式     |
| -v   | 显示同步过程 |
| -z   | 传输时压缩   |

+ 下载: rsync -avz 服务器IP:/服务器目录/file /本地目录   
  ```
  rsync -avz root@192.168.37.10:/filesrc/text.txt /filedst/
  ```     

+ 上传: rsync -avz /本地目录/file 服务器IP:/服务器目录/*  
  ```
  rsync -avz /filedst/test.txt root@192.168.37.10:/filesrc/
  ```
    
*ssh-keygen -t rsa -b 2048*  
*ssh-copy-id root@192.168.37.20*  

#### rsync服务端(NFS服务器)
```bash
[root@xy ~]# vim /etc/rsyncd.conf  
  address = 192.168.37.10 #rsync服务绑定IP
  port = 873
  log file =/var/log/rsyncd.log 
  pid file = /var/run/rsyncd.pid
  [web]
      comment = web directory backup
      path = /filesrc
      read only = no
      dont commpress = *.gz *.bz2
      auth users =user1   # 非系统用户, 自行创建
      secrets file = /etc/rsyncd_users.db
[root@xy ~]# vim /etc/rsyncd_users.db   
  user1:123456
[root@xy ~]# chmod 600 /etc/rsyncd_users.db 
[root@xy ~]# rsync --daemon  
[root@xy ~]# netstat -antp |grep :873  
[root@xy ~]# setfacl -m u:nobody:rwx /filesrc 
```

#### 客户端
```
[root@xy ~]# rsync -avz rsync://user1@192.168.37.10/filesrc /filedst      # 下载 
[root@xy ~]# rsync -avz /filedst/* rsync://user1@192.168.37.10/filesrc`   # 上传    
```

### rsync(基于xinetd) + inotifywait 实现单向实时同步：
| inotifywait 命令选项 | 说明               |
|----------------------|------------------|
| -m                   | 始终保持监听       |
| -r                   | 递归查询目录       |
| -q                   | 只打印监控事件信息 |

#### 服务端
```
[root@xy ~]# yum -y install gcc*  
[root@xy ~]# tar -xvf inotify-tools-3.14.tar.gz 
[root@xy ~]# cd inotify-tools-3.14.tar.gz
[root@xy ~]# ./configure && make make install  

# 监控动作：modify,create,attrib,move,delete 
[root@xy ~]# inotifywait -mrq -e 监控动作1,监控动作2 /监控目录 &     
[root@xy ~]# inotifywait -mrq -e create,delete,modify /filesrc &   
  #!/bin/bash  
  Inotfiy = "inotifywait -mrq -e create,delete,modify /filesrc"
  Rsync = "rsync -avz /filesrc/* root@192.168.37.20:/filedst"
  $Inotfiy | while read directory event file
  do
     $Rsync
  done  
```

### rsync(基于xinetd) + unison + inotify 实现双向实时同步：
#### 服务端(192.168.37.10)
```
[root@xy ~]# tar -xzvf inotify-tools-3.14.tar.gz  
[root@xy ~]# cd inotify-tools-3.14
[root@xy ~]# ./configure && make && make install  
[root@xy ~]# tar -xzvf ocaml-3.10.1.tar.gz 
[root@xy ~]# cd ocmal-3.10.1
[root@xy ~]# ./configure
[root@xy ~]# make world opt
[root@xy ~]# make install
[root@xy ~]# tar -xzvf unison-2.13.16.tar.gz
[root@xy ~]# cd unison-2.13.16
[root@xy ~]# make UISTYLE=text THREADS=true STATIC=true  
[root@xy ~]# cp unison /usr/local/bin 
  #!/bin/bash  
  Inotfiy = "inotifywait -mrq -e create,delete,modify /filesrc"
  Unison = "/usr/local/bin/unison -batch /filesrc ssh://192.168.37.20/filedst"
  $Inotfiy | while read directory event file
  do
     $Unison
  done
```

#### 客户端(192.168.37.20)
> 安装 inotify-tools-3.14.tar.gz，ocaml-3.10.1.tar.gz，unison-2.13.16.tar.gz
  
  ```bash
  #!/bin/bash  
  Inotfiy = "inotifywait -mrq -e create,delete,modify /filesrc"
  Unison = "/usr/local/bin/unison -batch /filedst ssh://192.168.37.10/filesrc"
  $Inotfiy | while read directory event file
  do
    $Unison
  done
  ```

## Linux 日志概述
### 系统常见日志文件
+ syslog服务
  * syslogd：系统
  * klogd：内核

| 日志文件              | 说明                                    |
|-----------------------|---------------------------------------|
| /var/log/cron         | 定时任务log                             |
| /var/log/cpus         | 打印信息log                             |
| /var/log/dmesg        | 内核自检log, `dmesg`                    |
| /var/log/btmp         | 错误登录log, 二进制格式, 用`lastb`查看  |
| /var/log/lastlog      | 最后一次登录时间log, `lastlog`查看      |
| /var/log/mailog       | 邮件log                                 |
| **/var/log/messages** | 系统重要信息log                         |
| /var/log/secure       | 验证与授权log                           |
| /var/log/wtmp         | 永久记录所有用户登录, `last`查看        |
| /var/run/utmp         | 当前已经登录用户信息, `w who users`查看 |
| /var/log/httpd        | RPM安装apache服务默认日志目录           |

### 日志格式: syslog 服务 
配置路径: `/etc/syslog.conf`  
配置格式: `日志服务[链接符号]日志等级	日志记录位置`
``` 
35 # Include all config files in /etc/rsyslog.d/
36 $IncludeConfig /etc/rsyslog.d/*.conf
54 *.info;mail.none;authpriv.none;cron.none      /var/log/messages 
55 authpriv.*                                   /var/log/secure
56 *.emerg                                      *   # 每个用户
60 mail.*                                      -/var/log/maillog    # 异步写入
```

| 日志等级（从低到高） | 说明(级别越低，信息越详细) |
|--------------------|-------------------------|
| debug              | 一般调试信息              |
| info               | 基本通知信息              |
| notice             | 普通信息                  |
| wraning            | 警告信息                  |
| err/error          | 错误信息                  |
| crit               | 大于err                   |
| alert              | 警告,大于crit             |
| emerg/panic        | 会导致系统不可用          |
| *                  | 所有日志等级              |
| none               | 和* 相反                  |

### 日志轮替 logrotate(切割,轮替)
> 旧日志移动开改名,同时建立新的空日志文件,当旧日志文件超出保存范围,会进行删除,系统自带配置文件`/etc/logrotate.conf`  

```
20 # no packages own wtmp and btmp -- we'll rotate them here
21 /var/log/wtmp {
22     monthly
23     create 0664 root utmp
24     minsize 1M
25     rotate 1
26 }
```

| 配置参数                | 说明                               |
|-------------------------|----------------------------------|
| daily                   | 日志轮替周期是每天                 |
| weekly                  | 每周                               |
| monthly                 | 每月                               |
| compress                | 日志轮替时,压缩旧日志              |
| rotate                  | 保留日志个数                       |
| create mode owner group | 建立新日志,指定权限与所有者/所属组 |
| mail address            | 发送邮件                           |
| missingok               | 日志不存在忽略日志警告信息         |
| notifempty              | 若日志为空,不进行轮替              |
| minsize                 | 轮替最小值                         |
| size                    | 大于size才会轮替                   |
| dateext                 | 使用日期作为轮替文件后缀           |
| sharedscripts           | 此关键字后脚本只执行一次           |
| prerotate/endscript     | 轮替前执行脚本                     |
| postrotate/endscript    | 轮替后执行脚本                     |

## ELK(Elasticsearch+Logstash+Kibana)
### ELK日志分析：<div id="ELK"></div>     
 
> **ELK**是三个开源软件的缩写，分别表示：**Elasticsearch、Logstash、Kibana**它们都是开源软件,新增了**FileBeat** ，轻量级的日志收集处理工具；

+ **Filebeat**：属于Beats
    - **Filebeat**：搜集文件数据 √
    - **Packetbeat**：搜集网络流量数据
    - **Topbeat**：搜集系统、进程和文件系统级别的CPU和内存使用情况  
    - **Winlogbeat**：搜集Windows事件日志数据
+ **Logstash(5044)**：负责日志的收集、分析、功率，支持大量数据获取方式，C/S架构，client 端安装在需要收集日志的主机上，server端负责将收集到的节点日志进行过滤发至Elastiserach上; 
+ **ElastiSearch(9200)**：开源分布式搜索引擎，提供搜集、分析、存储数据三大功能;
+ **Kibana(5601)**：为 Logstash 和 Elasticserach 提供Web 界面;
 
{% asset_img ELK.jpg [ELK] %} 
{% asset_img ELK-Filebeat.jpg [ELK-Filebeat] %}  

### 数据存储
#### 索引 分片 副本
* [参考](https://my.oschina.net/kenblog/blog/3009800)
* `index索引：`就类似于关系型数据库的`数据库`，数据库建立好，然后就把数据存到index中；
* `shard分片：`对于分布式的搜索引擎, **索引通常都会分解成不同部分**, 而这些分布在不同节点的数据就是分片,`一个分片只存储一部分数据`，所有分片加起来就是一个完整的索引数据；
  - 分片分为primary shard主分片和replica副本分片,一个索引可以创建多个分片数量，es默认创建的就是5个主分片数量，可以根据自己的实际业务确定主分片数量;
  - 注意的是主分片数量一旦确定创建就无法进行修改。
* `replica副本：`就是对主分片（Primary shard）的备份；
  - 每个主分片（primary shard）不会和副本分片（replica shard）存在于同一个节点中，有效的保证es的数据高可用性；

### ELK 服务端部署(192.168.37.10)
#### 安装包
```
[root@xy ~]# mkdir /elk;cd /elk  
[root@xy elk]# wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.2.3.tar.gz
[root@xy elk]# wget https://artifacts.elastic.co/downloads/logstash/logstash-6.2.3.tar.gz
[root@xy elk]# wget https://artifacts.elastic.co/downloads/kibana/kibana-6.2.3-linux-x86_64.tar.gz
[root@xy elk]# tar -xzvf elasticsearch-6.2.3.tar.gz 
[root@xy elk]# tar -xzvf logstash-6.2.3.tar.gz
[root@xy elk]# tar -xf kibana-6.2.3-linux-x86_64.tar.gz  
```

#### 配置 elasticserch 
```
[root@xy elk]# chown -Rf root:root kibana-6.2.3-linux-x86_64
[root@xy elk]# cp -a elasticsearch-6.2.3/ logstash-6.2.3/ kibana-6.2.3-linux-x86_64/ /usr/local
[root@xy elk]# yum install -y java-1.8*   # JAVA 环境
[root@xy elk]# useradd elasticsearch   
[root@xy elk]# chown elasticsearch:elasticsearch /usr/local/elasticsearch-6.2.3/
[root@xy elk]# su elasticsearch  # 以elasticsearch 用户运行
[elasticsearch@xy elasticsearch-6.2.3]$ ./bin/elasticsearch -d  
[elasticsearch@xy elasticsearch-6.2.3]$ netstat -antp  # 9200端口  
[elasticsearch@xy elasticsearch-6.2.3]$ cat /usr/local/elasticserch-6.2.3/logs/elasticsearch.log
[elasticsearch@xy elasticsearch-6.2.3]$ curl localhost:9200  
```

#### 配置 logstash  
```
[root@xy logstash-6.2.3]# vim /vendor/bundle/jruby/2.3.0/gems/logstash-patterns-core-4.1.2/patterns/grok-patterns   
  # Nginx log
  WZ ([^ ]*)
  NGINXACCESS %{IP:remote_ip} \- \- \[%{HTTPDATE:timestamp}\] "%{WORD:method} %{WZ:request} HTTP/%{NUMBER:httpversion}" %{NUMBER:status} %{NUMBER:bytes} %{QS:referer} %{QS:agent} %{QS:xforward}
   
[root@xy logstash-6.2.3]# vim /usr/local/logstash-6.2.3/default.conf 
  input {
      beats{
          port => "5044"
      }
  }
  # 数据过滤
  filter {
      grok {
          match => { "message" => "%{NGINXACCESS}" }
      }
      geoip {
          # nginx 客户端 ip
          source => "192.168.37.20"
      }
  }
  # 输出配置为本机的 9200 端口,这是elasticsearch 服务的监听端口
  output {
      elasticsearch {
          hosts => ["127.0.0.1:9200"]
      }
  }
    
[root@xy logstash-6.2.3]# nohup ./bin/logstash -f default.conf &
[root@xy logstash-6.2.3]# tail -f nohup.out
[root@xy logstash-6.2.3]# netstat -antp | grep 5044    
```

#### 配置 Kibana
```
[root@xy kibana-6.2.3-linux-x86_64]# vim /usr/local/kibana-6.2.3-linux-x86_64/config/kibana.yml  
  server.host: "192.168.37.10"
[root@xy kibana-6.2.3-linux-x86_64]# nohup ./bin/kibana &
[root@xy kibana-6.2.3-linux-x86_64]# tail -f nohup.out
[root@xy kibana-6.2.3-linux-x86_64]# netstat -antp | grep 5601  
# 测试：192.168.37.10:5601   # Kibana 测试地址
```

#### Nginx部署(192.168.37.20)
```
[root@xy ~]# yum install -y nginx  
[root@xy ~]# wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.2.3-linux-x86_64.tar.gz  
[root@xy ~]# tar -xzf ./filebeat-6.2.3-linux-x86_64.tar.gz -C /usr/local/  
[root@xy filebeat-6.2.3-linux-x86_64]# vim filebeat.yml  
  enable：false                 #修改为true
  paths：/var/log/*.log         #修改为/var/log/nginx/*.log
  #output.elasticsearch:        #将此行注释掉
  #hosts: ["localhost:9200"]    #将此行注释掉
  output.logstash:              #取消此行注释
  hosts: ["192.168.37.10:5044"] #取消此行注释并修改IP 地址为ELK 服务器地址
[root@xy filebeat-6.2.3-linux-x86_64]# nohup ./filebeat -e -c filebeat.yml &  
[root@xy filebeat-6.2.3-linux-x86_64]# tailf nohup.out  
```

{% asset_img ELK.png [ELK] %}  
{% asset_img ELK01.png [ELK配置-01] %}  
{% asset_img ELK02.png [ELK配置-02] %}  

### 设置服务自启动
```bash
#!bin/bash
# chkconfig: 2345 21  89
# description: elasticsearch

# JAVA_HOME=/usr/local/jdk1.8
ES_HOME=/usr/local/elasticsearch
case $1 in
    start) sudo -iu elasticsearch $ES_HOME/bin/elasticsearch &;;
    *)  echo "require start";;
esac
------------------------------------

#!/bin/bash
# chkconfig: 2345 50  50
# description: logstash

LS_HOME=/usr/local/logstash
case $1 in
    start)sudo -iu elasticsearch $LS_HOME/bin/logstash -f $LS_HOME/config &;;
    *) echo "require start";;
esac
-----------------------------------

#!/bin/bash
# chkconfig: 2345 98  02
# description: kibana

KIBANA_HOME=/usr/local/kibana
case $1 in
    start) $KIBANA_HOME/bin/kibana &;;
    *) echo "require start";;
esac
```

### tomcat 服务自启动
```bash
#!/bin/bash
# description: Tomcat8 Start Stop Restart
# processname: tomcat8
# chkconfig: 234 20 80

CATALINA_HOME=/usr/local/tomcat8/

case $1 in
    start)
        sh $CATALINA_HOME/bin/startup.sh
        ;;
    stop)
        sh $CATALINA_HOME/bin/shutdown.sh
        ;;
    restart)
        sh $CATALINA_HOME/bin/shutdown.sh
        sh $CATALINA_HOME/bin/startup.sh
        ;;
    *)
        echo 'please use : tomcat {start | stop | restart}'
        ;;
esac
exit 0
```